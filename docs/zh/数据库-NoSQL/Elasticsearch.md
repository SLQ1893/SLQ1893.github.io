## 1、什么是全文搜索引擎？

一般的数据分为两种，**结构化数据**和**非结构化数据**。

结构化数据是只有固定类型、格式、有限长度的数据，如存储在关系数据库中的常规类型的数据；

非结构化数据是指没有固定类型、格式、长度的数据，也叫全文数据，如文本、HTML、Word 文档、图片等；

结构化数据可以通过数据库引擎进行存储、建立索引快速搜索，**对于非结构数据（全文数据）的存储和搜索则需要全文搜索引擎。**

## 2、对于全文数据，有哪些搜索方法？

对全文数据的搜索主要有两种方法：

##### 1、顺序搜索

从头到尾按顺序进行全文搜索，效率太低。

##### 2、全文搜索

将全文数据中的一部分关键信息提取出来，然后重新组织成结构化的数据，然后再对有结构的数据进行搜索就会更快，这就是全文搜索的思路（全文索引）。

## 3、为什么需要全文搜索引擎？

虽然一般传统的关系数据库也支持全文搜索，但都很鸡肋，性能较差，也会影响整个数据库的性能和维护，所以需要一个专业的全文搜索引擎进行数据的存储、搜索。

全文搜索引擎如**Elasticsearch、Solr**等支持复杂的查询语法，可以进行模糊查询、近义词查询、布尔查询等多种形式的搜索。

另外，全文搜索引擎通常还包括**文本分析功能**，如分词、过滤停用词、词干提取等，这些功能可以帮助改进查询结果的相关性，提供更加精准的搜索体验。

全文搜索引擎通过其高效的数据处理能力、复杂的查询支持、可扩展的架构和用户友好的接口，极大地增强了数据检索的能力，为用户提供了快速、准确、灵活的搜索解决方案，这些特性使得全文搜索引擎成为处理现代大数据应用中不可或缺的工具。

## 4、什么时候建议使用全文搜索引擎？

##### 以下场合可以考虑使用全文搜索引擎：

1、要搜索的数据大多是非结构化数据；

2、要存储、分析、搜索的数据量非常巨大；

3、需要支持非常实时、可靠的全文搜索查询；

## 5、常用的搜索引擎有哪些？

常用的搜索引擎有以下三个：

1、Lucene

2、Solr（基于 Lucene）

3、Elasticsearch（基于 Lucene）----市场主流

## 6、Elasticsearch 是什么？

Elasticsearch 是 Apache 开源的，建立在 Apache Lucene 基础上的一个分布式、基于 RESTFul 风格的**数据分析和搜索引擎**，由 Java 语言开发，它拥有很方便的搜索、分析和探索数据的能力，**能够达到准实时搜索，稳定、可靠、快速，安装使用方便，能使数据在生产环境变得更有价值**。

**Elasticsearch 是目前最受企业欢迎的搜索引擎**，其次是 Apache Solr，也是基于 Lucene。

## 7、Elasticsearch、Solr、Lucene 的区别？

Lucene 它是 Apache 开源的全文检索引擎工具包（包含了索引结构、读写索引工具、相关性工具、排序等功能），它不是一个完整的全文检索引擎，而是一个全文检索引擎架构。

Solr 和 Elasticsearch 两个都是基于 Lucene 的开源全文搜索引擎，在 Lucene 其基础上进行了封装并提供了丰富的功能，它们都是完整的搜索引擎。

---

企业一般是直接使用 Solr 或者 Elasticsearch，而不是 Lucene！

## 8、Elasticsearch 和 Solr 怎么选？

![](/images/Elasticsearch/8.jpg)

其实选哪个都没问题，两个都是十分优秀的搜索引擎，只是现在 Elasticsearch 更火吧，用 Elasticsearch 也足够了，如果你正在用 Solr，那么请继续，不受影响。

## 9、Elasticsearch 的应用场景有哪些？

主要应用场景：

1、全文检索、高亮搜索、搜索推荐；

2、非结构化数据的分布式存储；

3、对海量数据进行近实时的分析、处理；

## 10、Elasticsearch 为什么被称为近实时搜索引擎？

Elasticsearch 被称为**近实时搜索引擎**，或者**准实时搜索引擎**，这是因为它不是实时搜索的。

新数据在被添加到 ES 后，需要一段短暂的时间才能被搜索到，这个时间一般在 1 秒左右，即它不会马上写入磁盘，会先存储在内存中，再定时写入到磁盘中，这就是为什么 Elasticsearch 被称为[**近实时搜索引擎**]的原因。

这种设计是为了提高系统的写入性能，因为频繁地将数据写入磁盘会消耗大量的 I/O 资源，而内存的写入速度要远远快于磁盘。

所以这种设计也带来了一个副作用，**那就是新添加的文档不能立即被搜索到，需要等待下一次刷新操作。**

总的来说，Elasticsearch 的准实时特性是其内部设计的一种权衡，旨在在写入性能和搜索实时性之间找到一个平衡。

## 11、Elasticsearch 近实时搜索的实现原理？

Elasticsearch 写入数据时，它不会马上写入磁盘，在磁盘之外还有两个内存区域：

- **Memory Buffer**：内存缓存区，它是 Elasticsearch 中用于暂存索引操作的内存区域。
- **File System Cache**：文件系统缓存，它是操作系统提供的一种缓存机制，它可以将磁盘 IO 操作暂存到内存中，从而提高读写性能。

具体实现原理和流程如下：

![](/images/Elasticsearch/11.jpg)

##### 1、写入内存缓存区

当新的文档被索引到 Elasticsearch 时，它们首先被写入到 Memory Buffer，同时添加事务日志（translog），用于防止意外情况导致数据丢失从而恢复数据。

> 此时，写入的数据还不能被搜索到。

##### 2、写入页面高速缓存

默认情况下，Elasticsearch 会每隔 1 秒将 Memory Buffer 中的新索引写入到一个新的段（segment）中，并刷新（refresh）到 File System Cache 中，然后清空 Memeory Buffer 中的数据。

> 此时，写入的数据可以被搜索到了。因为每个段（segment）文件其实就是一些[倒排索引]的集合，索引只有经过 refresh 操作后才能被搜索到。

##### 3、写入磁盘

File System Cache 也是缓存数据，最终还是要写入磁盘的，默认情况下，Elasticsearch 会将 File System Cache 中的数据同步写入（flush）到磁盘中，然后再清空事务日志文件（translog）。

flush 操作主要通过以下参数控制：

| 参数                                  | 说明                                   | 默认值  |
| ------------------------------------- | -------------------------------------- | ------- |
| index.translog.flush_threshold_period | 每个多长时间执行一次 flush             | 30 分钟 |
| index.translog.flush_threshoe_size    | 事务日志文件达到预设大小执行一次 flush | 512M    |

## 12、Elasticsearch 如何做到实时搜索？

可以通过手动执行 refresh 操作，将 Memory Buffer 中的数据立即写入到 File System Cache 中去。

一般有以下两种方式：

##### 1、写入文档后立即执行 refresh 操作

> PUT /test/\_doc/1?refresh
>
> {"test": "test"}
>
> PUT /test/\_doc/2?refresh=true
>
> {"test": "test"}

##### 2、整个/单个索引执行 refresh 操作

> PUT /test/\_doc/1?refresh
>
> POST /test/\_refresh

> 需要注意的是：
>
> 频繁执行 refresh 操作会消耗大量的 IO 资源，可能会影响 Elasticsearch 的性能。
>
> 所以，除非有特殊的需求，否则我们不需要手动执行 refresh 操作，而是让 Elasticsearch 按照默认的频率自动执行 refresh 操作。

## 13、Elasticsearch 写入的数据什么时候才可以搜索到？

Elasticsearch 写入的数据只有经过**refresh**操作后，存储到文件系统缓存（File System Cache）中才能被搜索到。

## 14、Elasticsearch 总体架构描述一下？

总体架构图如下：

![](/images/Elasticsearch/14.jpg)

从下往上依次是：

| 模块                         | 说明               |
| ---------------------------- | ------------------ |
| Gateway                      | 文件系统           |
| Distributed Lucene Directory | 分布式 Lucene 目录 |
| Index Moudle                 | 索引模块           |
| Search Moudle                | 搜索模块           |
| Mapping                      | 映射               |
| River                        | 数据源             |
| Discovery                    | 节点发现模块       |
| Scripting                    | 脚本语言           |
| 3rd plugins                  | 第三方插件         |
| Transport                    | 内部交互节点       |
| JMX                          | 监控               |
| Java（Netty）                | 通信框架           |
| RESTful Style API            | 前端请求 API       |

## 15、Elasticsearch 如何选择硬件配置？

为确保 Elasticsearch 集群的高效运行，关注一下几个核心硬件配置是非常关键的：

##### CPU

推荐至少使用 8 核心的 CPU，以支持 Elasticsearch 的并行处理需求，特别是在执行复杂查询和聚合操作时。

##### 内存

1、建议为 Elasticsearch 分配尽可能多的内存，可以根据实际数据量，确保服务器具有足够的物理内存，以支持除 JVM 堆外的文件系统缓存，这对提升索引和查询性能至关重要。

2、建议将服务器总内存的 50%分配给 JVM 堆，但不超过 32GB，已利用 JVM 的压缩指针优化。因为超过 32GB 会导致 JVM 使用更大的指针，减低内存利用率。

##### 磁盘

1、推荐使用 SSD 固态硬盘，因为 SSD 在处理 IO 密集型操作时，读写速度优于传统的机械硬盘。

2、根据数据的预期来选择适当的磁盘容量，考虑到索引数据、原始数据及日志文件的存储需求。

## 16、Elasticsearch 的交互方式是怎样的？

可以使用**RESTful API**通过端口**9200**和 Elasticsearch 进行通信，除了可以使用 web 客户端访问 Elasticsearch，你甚至可以使用`curl`命令来和 Elasticsearch 交互。

Elasticsearch 支持的客户端有这些：

![](/images/Elasticsearch/16.jpg)

## 17、Elasticsearch 怎么关闭？

先查找进程 ID：

> jps| grep Elasticsearch

得到 PID 再使用：

> kill -9 xxx

## 18、Elasticsearch 怎么启动？

使用命令：

> ./bin/elasticsearch -d -p pid

-d：表示以守护线程运行（可选）

-p：在日志文件中记录进程 ID（可选）

## 19、Elasticsearch 怎么测试是否启动成功？

直接访问：

> http://localhost:9200

![](/images/Elasticsearch/19_1.jpg)

或者使用命令：

> curl 'http://localhost:9200/?pretty'

会得到以下响应：

![](/images/Elasticsearch/19_2.jpg)

## 20、Elasticsearch 集群的启动过程？

Elasticsearch 集群大概启动过程如下：

##### 1、节点发现

当启动 Elasticsearch 节点时，首先会通过[**单播**]的方式来发现同一个集群里的其他节点，**这一过程是通过在配置文件中提供一部分节点的地址来实现的**，节点启动后会尝试与这些地址建立连接，从而发现集群中的其他节点。

##### 2、选举主节点

在节点发现完成后，**集群中的节点会选举出一个主节点**，主节点的主要职责是负责管理集群的全局状态，包括创建和删除索引，以及分配分片等。

主节点的选举基于一个简单的多数投票机制，**需要参选投票节点数过半，且最终得票数过半。**

##### 3、分配分片

主节点选举完成后，主节点会开始检查所有的索引分片，并决定哪些分片将被用作主分片，**当所有的主分片都被正确地分配后，集群会进入[黄色]状态。**

在此状态下，尽管还有一些副本分片没有被分配，但是集群已经可以处理查询请求了。

##### 4、分配副本

主节点会继续寻找可用地节点，并将剩余的副本分片分配到这些节点上，**当所有的主分片和副本分片都被正确地分配后，集群会进入绿色（Green）状态。**

在此状态下，集群已经完全可用了，可以正常处理所有的读写请求。

## 21、Elasticsearch 脑裂问题是什么情况？

脑裂问题是指，由于某些节点之间的网络通信出现问题， 或者 Master 节点负载过大停止响应，导致一些节点以为 Master 节点已经挂了，**所以又重新选举了新的 Master 节点，从而同时出现两个 Master**，导致集群信息混乱，这样就会造成数据不一致的问题。

## 22、Elasticsearch 如何避免出现脑裂问题？

##### 1、网络问题：

修复网络，重启集群。

##### 2、主节点负载过大：

（1）设置 3 台以上的节点作为 Master 节点，这些节点只负责成为主节点；

（2）根据数据量设置一批 Data 节点，只负责存储数据；

（3）设置一批 Client 节点，只负责处理用户请求；

（4）还有两个参数的修改可以减少脑裂问题的出现；

- **discovery.zen.ping_timeout**：如果一个节点发现 master 节点在 3 秒（默认）之内没有响应，那么会认为 Master 挂了，可以增大这个值，从一定程度上会减少误判；
- **discovery.zen.minimum_master_nodes**：形成一个有效集群所需的最小主节点数，官方的推荐值是(N/2)+1，其中 N 是具有 Master 资格的节点的数量。

## 23、Elasticsearch 中的分析器是什么？

分析器是指文档在加入倒排索引之前，Elasticsearch 需要经过一系列的分析处理操作，比如：

- 字符过滤（字符过滤器）
- 文本切分为分词（分词器）
- 分词过滤（分词过滤器）
- 分词索引

所以分析器其中又有字符过滤器、分词器、分词过滤器等。

## 24、Elasticsearch 中的分词器是什么？

分词器负责将文本字符串切分成一个个小块，即分词（token）。

比如标准分词器可以根据空格将文本切成一个个分词。

文本字符串为：

> I love java questions forever

切分后的分词为：

- I
- love
- java
- questions
- forever

## 25、Elasticsearch 中的分词多滤器是什么？

文本被切成为一个个分词后，Elasticsearch 就会对每个分词再进行过滤，即---**分词过滤器**。

分词过滤器可以对分词进行一定的修改、或者删除，比如常见的小写分词过滤器，它可以把分词转换为小写，如把“Java”转换为“java”，我在搜索“java”的时候就可以搜索到“Java”的文档。

## 26、Elasticsearch 内置的分析器有哪些？

Elasticsearch 内置的分析器有 8 个：

| 分析器               | 名称               | 说明 |
| -------------------- | ------------------ | ---- |
| Standard Analyzer    | 标准分析器（默认） |      |
| Simple Analyzer      | 简单分析器         |      |
| stop Analyzer        | 停用词空白分析器   |      |
| whitespace Analyzer  | 空白分析器         |      |
| keyword Analyzer     | 关键词分析器       |      |
| pattern Analyzer     | 模式分析器         |      |
| Language Analyzers   | 多语言分析器       |      |
| Fingerprint Analyzer | 雪球分析器         |      |

## 27、Elasticsearch 内置的分词器有哪些？

Elasticsearch 内置的分词器：

| 分词器               | 名称       | description |
| -------------------- | ---------- | ----------- |
| Standrad Tokenizer   | 标准分词器 |             |
| Letter Tokenizer     | 字母分词器 |             |
| Lowercase Tokenizer  | 小写分词器 |             |
| Whitespace Tokenizer | 空白分词器 |             |
| ...                  | ...        | ...         |

> Elasticsearch 7.x 一共有 15 种分词器

![](/images/Elasticsearch/27.jpg)

## 28、Elasticsearch 在分析之前首先用到了什么？

Elasticsearch 在分析之前，首先用到了**字符过滤器**。

## 29、Elasticsearch 中的字符过滤器是什么？

字符过滤器负责将特定的字符序列转换为其他的字符序列，比如：

- I love u => I love you
- I love u 2 => I love you too
- & => and
- ...

## 30、Elasticsearch 一个分析器有多少个分词器？

Elasticsearch 一个分析器中的分词器只能是 1 个。

## 31、Elasticsearch 一个分析器有多少个分词过滤器？

Elasticsearch 一个分析器中分词过滤器可以是 0 个或者多个。

## 32、Elasticsearch 一个分析器有多少个字符过滤器？

Elasticsearch 一个分析器中的字符过滤器可以是 0 个或者多个。

## 33、Elasticsearch 数据逻辑结构是怎样的？

Elasticsearch 数据逻辑结构为：

> Index（索引）/ Type（类型） / Docuement（文档）

可以与关系数据库的对比理解下：

![](/images/Elasticsearch/33.jpg)

Type 已经被弃用，后续的版本即将废除。

## 34、Elasticsearch 中的索引是指什么？

Elasticsearch 中的一个**索引（名词）**相当于 MySQL 中的一个**数据库**，是一个存储关系型文档的地方。索引（index）的复数词为 indices 或 indexes。

**索引（动词）**一个文档就是指存储一个文档到一个索引中，类似于 SQL 语句中的`INSERT`关键词。

## 35、Elasticsearch 索引是可变的吗？为什么？

Elasticsearch 中的索引是不可变的，索引的结构一旦创建，就不能改变。

##### 主要还是为了提升性能：

（1）不能修改就不需要对索引加锁；

（2）已经查询出来的数据就可以一直保存在缓存中；

（3）可以节省 CPU 和 IO 开销；

## 36、Elasticsearch 使用的是什么索引结构？

Elasticsearch 使用一种称为**倒排索引**d 额结构，它适用于快速的全文搜索。

## 37、Elasticsearch 中的倒排索引是什么？

##### 通俗易懂的理解：

如果说**正排索引**是根据文档找所有关键字所在的内容，那么**倒排索引**即是根据关键字内容反向找对应所在的所有文档。

**正排索引**：document -> words

**倒排索引**：word -> documents

---

Elasticsearch 使用的就是**倒排索引**的结构，相当于 MySQL 中的 B 树（B-tree）索引，以便于快速检索数据。

## 38、Elasticsearch 倒排索引结构是怎样的？

一个**倒排索引**由文档中所有不重复的列表构成，对于其中每个词，有一个包含它的文档列表。

比如现在有两个文档，每个文档的`content`包含如下内容：

1. The quick brown fox jumped over the lazy dog
2. Quick brown foxes leap over lazy dogs in summer

根据每个单独的词创建倒排索引：

![](/images/Elasticsearch/38_1.jpg)

现在搜索`quick brown`，我们只需要查找包含每个词条的文档：

![](/images/Elasticsearch/38_2.jpg)

## 39、Elasticsearch 倒排索引的底层实现是？

倒排索引的底层实现是基于[FST (Finite State Transducer)]的数据结构。

##### FST 有两个优点：

##### 1、空间占用小

FST 通过**共享前缀和后缀来压缩存储空间**，这使得它在存储大量的字符串时，能够节省大量的存储空间。这对于倒排索引这种需要存储大量词项的应用来说，是非常重要的。

##### 2、查询速度快

FST 查询时间复杂度仅有**O（len(term)）**，在倒排索引中，我们需要快速找到一个词项对应的文档列表，FST 能够提供这样的快速查询。

## 40、Elasticsearch 怎么删除一个索引？

参考命令：

> curl -X DELETE "localhost:9200/java"

返回结果：

```json
{ "acknowledged": true }
```

## 41、Elasticsearch 怎么删除全部索引？

参考命令：

> curl -X DELETE "localhost:9200/\_all"

命令很危险，会删除所有索引和文档，可以在 Elasticsearch 配置文件中设置禁用\_all 操作和通配符操作。

![](/images/Elasticsearch/41.jpg)

## 42、Elasticsearch 怎么关闭一个索引？

关闭索引后就不能读写文档了，但不至于数据被删除，所以需要用到的时候可以再次打开它。

##### 关闭索引命令：

> curl -X POST "localhost:9200/java/\_close"

返回结果：

```json
{
  "acknowledged": true,
  "shards_acknowledged": true,
  "indices": { "closed": true }
}
```

##### 打开索引命令：

> surl -X POST "localhost:9200/java/\_open"

返回结果：

```json
{ "acknowledged": true, "shards_acknowledged": true }
```

## 43、Elasticsearch 支持多少个 Type？

Type 已经准备移除了！！！

Elasticsearch 6.0 只能支持一个 index 一个 type 了，7.0 版本新增了一个参数`include_type_name`，默认是`true`，用来兼容老的数据映射类型，到 8.0 的时候，可能会默认改成`false`，也就是不包含 type 信息了，这个是 type 用于移除的一个开关。

## 44、Elasticsearch 为什么要启用 Type？

在关系型数据库中，Table 是独立存储的，但在 Elasticsearch 中，同一个 Index，不同的 Type 是存储同一个 Lucene 的索引文件中的。

这就有一个问题，如果两个 Type 有同一个字段（married），两个 Type 里的 married 字段就必须是一样的字段定义，存储仅有小部分字段相同或者全部字段都不相同的文档，这将会导致数据稀疏，影响数据压缩的能力。

## 45、Elasticsearch 中的文档是指什么？

Elasticsearch 中的数据是**面向文档**的，一个文档代表关系数据库中的一行数据，它是对文档进行索引、检索、排序和过滤，而不是对行、或者列数据，而**JSON**则是作为文档序列化格式。

下面这个 JSON 文档代表了一个 user 对象：

![](/images/Elasticsearch/45.jpg)

## 46、Elasticsearch 文档是可变的吗？为什么？

在 Elasticsearch 中文档是**不可变**的，不能修改它们。

因为 Elasticsearch 是基于 Lucene 的，Lucene 为了实现高索引速度，而使用段架构，一堆文件保留在一个段中，其中每个段是磁盘中的单个文件，由于写入文件之间的工作非常繁重，因此将一个段设为不可变的，以便所有后续写入都转到新的段。

比如，如果更新一个现有的文档，ES 会把旧版本的文档被标记删除，然后把新版本的文档存储到一个新的段中，多个版本的文档可能都会被一个查询匹配到，但被删除的旧版本的文档在返回结构集之前会被剔除掉。

## 47、Elasticsearch 根据什么来确认唯一文档？

Elasticsearch 数据逻辑结构是怎样的？

## 48、Elasticsearch 文档有哪些元数据？

| 元数据    | 说明               |
| --------- | ------------------ |
| \_index   | 文档索引           |
| \_type    | 文档类型           |
| \_id      | 文档 ID            |
| \_version | 文档版本号         |
| \_source  | 文档原始 JSON 数据 |
| \_score   | 文档打分           |

## 49、Elasticsearch 怎么索引一个文档？

参考命令：

![](/images/Elasticsearch/49_1.jpg)

返回结果：

![](/images/Elasticsearch/49_2.jpg)

## 50、Elasticsearch 文档怎么自动生成 ID？

使用 POST 方式，同时文档 ID 处进行省略：

![](/images/Elasticsearch/50_1.jpg)

结果返回：

![](/images/Elasticsearch/50_2.jpg)

ID 自动生成了。

## 51、Elasticsearch 中的`_uid`和`_id`的区别？

Elasticsearch 内部是使用\_uid 进行存储和索引的。

`_id`和`_type`都是一种抽象的概念，所以\_id 通常是从`_uid`中提取出来的，但是`_type`必须单独建立索引，以便在搜索特定类型的文档时能够根据类型轻松地过滤文档。

## 52、Elasticsearch 修改文档的方式及原理？

前面说了 Elasticsearch 中的文档是不可改变的，不能修改它们。

##### 修改文档有两种方式：

##### 1、全部替换

先把原来的文档标记为逻辑删除：deleted，又重新创建一个新文档。

##### 2、部分替换

先查询出原有文档，并替换部分字段的值，再把原来的文档标记为逻辑删除：deleted，再重新创建一个新文档。

> 标记为 deleted 的文档，随着数据的增多，ES 会在后台彻底删除掉。

## 53、Elasticsearch 删除文档的方式及原理？

前面说了 Elasticsearch 中的文档是**不可改变**的，不能修改它们。

##### 删除文档有两种方式：

（1）先把原来的文档标记为逻辑删除：deleted，不再被搜索返回；

（2）标记为 delted 的文档，随着数据的增多，ES 会在后台彻底删除掉；

## 54、Elasticsearch 中的评分怎么理解？

Elasticsearch 有个评分机制，它根据不同的因素来确定文档的得分，得分越高表示文档的相关性越高，相关性越高的文档会排在前面优先返回。

![](/images/Elasticsearch/54.jpg)

## 55、Elasticsearch 评分模型有哪些？

Elasticsearch 最常用的评分模型是：

- TF-IDF：向量空间模型（Elasticsearch 5.0 之前默认）
- BM25：概率模型（Elasticsearch 5.0+默认）

## 56、Elasticsearch 中的 TF-IDF 算法怎么理解？

##### TF：term frequency，词频算法。

一个分词在 index 的某个文档中出现的次数越多，则权重越高。

##### IDF：inverse document frequency，逆文本频率指数算法。

一个分词在 index 的不同文档中出现越多的次数，则权重越低。

## 57、Elasticsearch 中的 BM25 算法怎么理解？

##### BM25 全称为：Okapi BM25。

BM25 基于 TF-IDF 算法做了改进，是一种基于概率模型的文档检索算法，是 Elasticsearch 5.0+默认的评分算法。

BM25 算法中有两个可调节的参数，可以进行一些特殊搜索场景的调优。

![](/images/Elasticsearch/57.jpg)

## 58、Elasticsearch 的搜索过程简述一下？

Elasticsearch 的搜索过程可以分为**Query + fetch** 两个阶段。

##### Query：

1、数据分散在不同的分片中，所以需要每个分片在本地执行搜索；

2、分片搜索完，会将结果数据（ID、排序）放到各自的优先队列中；

3、分片再将各自优先队列的数据发给协调节点（接收客户端请求的节点），协调节点再进行最终排序（比如：10 个分片 \* 查询前 10 条数据 = 100 条数据，最后生成最终排序后的前 10 条数据）；

##### Fetch：

协调节点根据文档 ID 向相应的分片发送获取所有文档的请求，获取完之后最终返回给客户端。

## 59、Elasticsearch 怎么根据 ID 检索文档？

参考命令：

> curl -X GET "localhost:9200/java/user/1?pretty"

返回结果：

![](/images/Elasticsearch/59.jpg)

## 60、Elasticsearch 怎么根据某个字段检索文档？

如检查 last_name 为'Smith'的文档：

> curl -X GET "localhost:9200/java/user/\_search?q=last_name:Smith&pretty"

或者是这种用法：

![](/images/Elasticsearch/60.jpg)

## 61、Elasticsearch 怎么多条件检索文档？

参考命令：

![](/images/Elasticsearch/61_1.jpg)
使用 bool 查询，支持 must/must_not/should/filter

![](/images/Elasticsearch/61_2.jpg)

## 62、Elasticsearch 搜索结果怎么按年龄排序？

参考命令：

![](/images/Elasticsearch/62.jpg)

如上，查找 18 岁以上的所有人员并按年龄倒序展示。

## 63、Elasticsearch 怎么进行短语检索？

使用**match**搜索"**Yue Yang**"的用户：

![](/images/Elasticsearch/63_1.jpg)

这样就会把"**Yue Yang**"、"**Hen Yang**"、"**Yi Yang**"等相关的用户全部查出来。

---

怎么只查来自”**Yue Yang**“的呢？

查考命令：

![](/images/Elasticsearch/63_2.jpg)

使用**match_phrase**进行短语检索。

## 64、Elasticsearch 怎么进行高亮检索？

参考命令：

![](/images/Elasticsearch/64_1.jpg)

加入`highlight`条件即可。

返回结果多了一个`highlight`部分。这个部分包含了`from`属性匹配的文本片段，并以 HTML 标签`<em></em>`封装。

## 65、Elasticsearch 怎么检索爱好打球的用户？

参考命令：

![](/images/Elasticsearch/65.jpg)

interests 在文档中是个数组，这时候会返回所有打球的用户，包括以下爱好的用户：

- 打球（优先级最高，排最前面）
- 打羽毛球
- 打篮球

## 66、Elasticsearch 怎么检索爱好钓鱼的用户？

参考命令：

![](/images/Elasticsearch/66.jpg)

intersts 在文档中是个数组。

## 67、Elasticsearch 检索怎么返回指定的字段？

参考命令：

![](/images/Elasticsearch/67.jpg)

用`\_source`参数指定包含、排除即可。

## 68、Elasticsearch 怎么更新部分文档？

参考命令：

![](/images/Elasticsearch/68.jpg)

POST + \_update + doc 即可。

## 69、Elasticsearch 怎么更新整个文档？

参考命令：

![](/images/Elasticsearch/69.jpg)

PUT/POST 时带上 ID，如果文档已经存在就会更新整个文档。

## 70、Elasticsearch 怎么删除一个文档？

参考命令：

> curl -X DELETE "localhost:9200/java/user/4?pretty"

返回结果：

![](/images/Elasticsearch/70.jpg)

## 71、Elasticsearch 并发更新文档冲突怎么办？

在使用 Elasticsearch 进行数据更新时，可能会遇到并发更新导致的版本冲突问题，这种情况通常发生在多个进程或用户同时尝试更新同一文档时。

可以在更新时，通过设置参数

`retry_on_conflict`来自动完成重试操作：

> POST /test/1/\_update?retry_on_conflict=3

这里设置了冲突时重试 3 次，不设置不会重试。在应用层面，你也可以捕获版本冲突的异常，并根据业务需求决定是否重试更新操作。

## 72、Elasticsearch 并发控制是怎么实现的？

Elasticsearch 支持并发控制特性，每个文档都会有一个版本号（\_version）

![](/images/Elasticsearch/72_1.jpg)

每次索引、更新文档成功后版本号都会+1，并且每次修改文档的时候会和当前的版本号作比较，版本号一致才进行更新，不一致就更新失败，**其实这就是一种乐观锁的实现。**

---

你可以在更新操作中指定期望的版本号，Elasticsearch 会检查当前文档的版本号是否与指定的版本号匹配：

- 如果匹配，更新操作会成功，并且版本号递增。
- 如果不匹配，表示文档已被其他操作更新，Elasticsearch 将拒绝当前更新操作并返回版本冲突错误。

示例代码：

![](/images/Elasticsearch/72_2.jpg)

## 73、Elasticsearch 集群、节点、分片和副本的关系？

##### 关系总结：

- **集群**是多个节点的集合。
- **节点**是运行 Elasticsearch 实例的服务器，每个节点可包含多个分片。
- **分片**是数据的实际物理分割，每个索引由多个分片组成。
- **副本**是分片的拷贝，用于数据的冗余和查询性能的提升。

如图所示：

![](/images/Elasticsearch/73.jpg)

一个集群有 3 个节点，3 个主分片，每个主分片各自有 2 个副本。

为了防止单点故障，每个节点会有其他节点的副本，主分片和副本不会出现在同一个节点上。

## 74、Elasticsearch 中的节点是指什么？

Elasticsearch 集群有多个节点组成，组成一个分布式集群。节点就是一个 Elasticsearch 实例，即一个 Java 进程，每台机器都可以启动多个节点，但生产环境中建议一台机器只启动一个。

## 75、Elasticsearch 有哪些节点类型及作用？

Elasticsearch 集群中有多种类型的节点，每种节点都有其特定的职责和功能。

##### 1、主节点

主节点负责集群的管理和协调，包括创建或删除索引，跟踪哪些节点是集群的一部分，以及决定哪些分片分配给哪些节点。

> 主节点对于集群的健康和稳定至关重要。

##### 2、数据节点

数据节点存储数据，执行数据相关的 CRUD 操作和搜索聚合等。

##### 3、协调节点

协调节点主要负责将客户端请求路由到正确的节点，并将这些节点的响应汇总返回给客户端。

> 任何节点都可以充当协调节点。

以上是最主要的 3 种节点，另外还有像摄取节点、机器学习节点、跨集群复制节点等等。

## 76、Elasticsearch 节点怎么分配比较合适？

##### 在生产集群环境中，建议可以对节点职责进行划分：

（1）设置 3 台以上的节点作为 Master 节点，这些节点只负责成为主节点；

（2）根据数据量设置一批 Data 节点，只负责存储数据；

（3）设置一批 Client 节点，只负责处理用户请求；

## 77、Elasticsearch 主节点选举是怎样进行的？

前置条件：

1、只有是候选主节点才能参与选举成为主节点。

2、防止脑裂，需要设置最小主节点数。

##### 选举流程大概如下：

1、检查并确认候选主节点数是否达标。

2、对所有候选主节点根据 nodeId 字典进行排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个节点投票为 master 节点。

3、如果对某个节点达到投票数：候选主节点数 n/2 +1，并且该节点也投了自己，那么这个节点就选举为 master 节点了，否则会重新选举直到满足条件。

## 78、Elasticsearch 节点发现采用的是什么通信机制？

在 Elasticsearch 的节点发现过程中，主要使用的是[**单播**]的方式。

几种通信方式说明：

- **单播**：一对一的通信方式。
- **多播**：一对多的通信方式。
- **广播**：一对所有的通信方式。

虽然单播在节点发现的过程种可能会比多播更慢一些，但是由于其在**兼容性、安全性、控制性和稳定性**等方面的优势，所以 Elasticsearch 选择了[**单播**]作为主要的节点发现机制。

## 79、Elasticsearch 的请求必须发送到主节点吗？

##### 不对，Elasticsearch 的请求并不必须发送到主节点。

在 Elasticsearch 种，任何节点都可以接收来自客户端的请求，当一个节点接收到请求时，它会扮演协调节点的角色，协调节点会根据集群的状态和请求的类型，将请求路由到适当的节点上去执行。

比如有以下请求：

- 如果是一个搜索请求，协调节点会将请求路由到存储有相关数据的数据节点上去执行，并将结果返回给客户端。
- 如果是一个创建索引的请求，协调节点会将请求路由到主节点去执行。

所以，客户端可以将请求发送到集群中的任何节点，而不仅仅是主节点。

这种设计使得 Elasticsearch 具有很高的可伸缩性和容错性，因为即使某个节点出现故障，客户端仍然可以通过其他节点来访问和操作集群。

## 80、Elasticsearch 中的最大节点数怎么计算？

> 最大节点数 = 分片数 \* （副本数 + 1）

比如有 10 个分片，每个分片有 2 个副本，那最大节点数是 10 \* （2 + 1） = 30。

## 81、Elasticsearch 中的分片和副本是指什么？

在 Elasticsearch 中，分片（Shard）和副本（Replica）是 Elasticsearch 实现数据分布和冗余备份的基础，**分片用来解决数据水平扩展问题，副本是分主片的拷贝，用来解决高可用问题。**

##### 1、分片（Shard）

分片是 Elasticsearch 进行数据分布的最小单位。当你创建一个索引时，你可以定义这个索引包含多少个分片。每个分片本质上是一个独立的“索引”，它可以承载部分数据，可以被单独查询，可以在 Elasticsearch 集群中的节点间迁移。

分片有两种类型：**主分片（Primary Shard）和副本分片（Replica Shard）**。

> 主分片在创建索引时就已经确定，用于存储数据，一个索引的主分片数量在创建后不能更改。

##### 2、副本（Replica）

副本是主分片的复制品，副本不仅可以在主分片出现问题时提供冗余备份，保证数据的安全，还可以提高查询的性能，因为查询可以在所有可用的主分片和副本分片上并行执行。

> 一个索引的副本数量可以在创建后动态更改，每个主分片可以有零个或多个副本，副本分片永远不会和它的主分片放在同一个节点上。

## 82、Elasticsearch 索引的默认分片数是多少？

这个要分不同版本来回答：

- 在**Elasticsearch 6.x**及之前的版本中，创建新索引时，**默认会创建 5 个主分片和 1 个副本分片。**
- 从**Elasticsearch 7.x**开始，这个默认值已经被改为**1 个主分片和 1 个副本分片**。

这个默认设置可以通过修改 Elasticsearch 的配置文件或者在创建索引时指定`number_of_shards`和`number_of_replicas`参数来进行更改。

> 需要注意的是：
>
> 一旦索引创建后，主分片的数量就不能在改变，而副本分片的数量则可以在后续进行调整。所以在创建索引时，需要根据数据量和查询负载等因素，合理设置主分片的数量。

## 83、Elasticsearch 中的过度分配怎么理解？有什么影响？

在 Elasticsearch 中，过度分配（Overallocation）是指为了提高系统的容错能力和查询性能，故意创建比实际需要更多的分片。**每个索引都可以被分为多个分片，每个分片都可以有一个或多个副本。**

##### 过度分配有什么好处？

1、如果一个节点失败，那么该节点上的分片副本可以在其他节点上提供服务，从而保证系统的可用性。

2、由于查询可以在多个分片上并行执行，所以增加分片数量可以提高查询性能。

##### 过度分配有什么影响？

1、每个分片都需要消耗一定的系统资源，如 CPU、内存和磁盘空间，所以，过度分配可能会导致系统资源的浪费，降低系统的整体性能。

2、过多的分片会增加集群的管理复杂性，比如分片的路由、平衡和恢复等。如果集群中的分片数量过多，可能会导致集群状态变得不稳定。

3、虽然更多的分片可以提高查询性能，但是如果分片数量过多，反而可能会降低索引和查询的性能。因为每次索引或查询操作都需要在所有相关的分片上执行，分片数量过多会增加协调和网络传输的开销。

所以，我们在设计 Elasticsearch 系统时，需要根据实际需求和资源情况，合理地设置分片数量，避免过度分配。

## 84、Elasticsearch 分片算法地原理？

Elasticsearch 分片算法原理，即路由计算，用于确定文档应该存储在哪个分片上。

每当向 Elasticsearch 索引一个文档时，Elasticsearch 都会使用一个特定的算法来计算这个文档应该被分配到哪个分片。

这个过程确保了数据地均匀分布性，以及在执行搜索查询时，也可以快速定位到包含相关文档地分片。

路由计算地基本原理：

##### 1、默认路由

如果没有指定路由值，Elasticsearch 默认使用文档的`_id`作为路由值，这保证了具有相同`_id`地文档总是被路由到同一个分片，这对于更新和删除操作至关重要，因为这些操作需要定位到文档地确切位置。

##### 2、路由值到分片的映射

Elasticsearch 使用简单的哈希函数对路由值进行哈希计算，然后将得到的哈希值与分片总数进行模运算（取余数），以确定目标分片的索引。

分片索引计算公式为：

> shard = hash(routing) % number_of_primary_shards

参数解释：

- shard：分片索引。
- routing：路由值，默认是文档的\_id，可以配置。
- number_of_primary_shards：主分片的数量。

然后所有核心的文档操作 API 都能接受一个 routing 路由参数，在进行 API 操作时可以根据这个路由参数到指定的分片进行操作。

如以下示例：

> PUT /user/\_doc/1?routing=user
>
> {
>
> ​ "name": "Jhon",
>
> ​ ...
>
> }

当使用路由参数时，具有相同路由值的所有文档将被索引到相同的分片中。

这种方法在处理相关联的文档时非常有用，比如，你可以将同一用户的所有数据，全部都存储在同一个分片中，这样可以优化查询性能。

## 85、Elasticsearch 有个索引有 50 个分片，搜索流程是怎样的？

当一个 Elasticsearch 索引配置了 50 个分片时，意味着这个索引的数据被水平分割成了 50 个部分，每个部分都可以独立存储、管理和搜索。

在处理搜索请求时，Elasticsearch 会采取以下步骤来确保高效和准确的数据检索。

##### 1、请求分发

当客户端向 Elasticsearch 发送搜索请求时，请求首先被路由到集群中的一个节点。这个节点被称为协调节点，协调节点的职责是接收客户端请求，然后根据集群的当前状态决定如何处理这个请求。

##### 2、查询分片

协调节点会将这个查询广播到这个索引的每个分片上，每个分片执行搜索请求并返回结果到协调节点。

##### 3、结果汇总

协调节点对所有分片返回的结果进行汇总、排序等操作，以生成最终的搜索结果。

## 86、Elasticsearch 默认在哪个分片执行操作？

##### 读操作

---

默认情况下，Elasticsearch 的查询并不会在固定某个特定的分片上执行操作，**而是在可用的主分片和副本之间进行负载均衡，选择最佳的分片来处理查询请求。**

> 假设我们有一个包含 3 个主分片有 1 个副本的索引。
>
> 查询请求发送时，Elasticsearch 会评估所有 6 个分片（3 个主分片 + 3 副本分片）的当前状态和负载，然后选择一个最佳的分片来处理查询请求。

这种选择机制基于多个因素，如分片的当前负载、响应时间等，目的是优化查询的性能和响应速度，同时也避免了某个节点或分片过载。

##### 写操作

Elasticsearch 的写请求，如索引和更新，**这些写操作只能由主分片处理**， 每个写操作后，数据会被复制到副本分片，确保数据的持久化和冗余。

## 87、Elasticsearch 分片和副本是如何保证数据一致性的？

当一个写请求发送到 Elasticsearch 某个协调节点时：

##### 1、请求路由

协调节点根据文档的 ID 通过哈希算法决定该文档属于哪一个主分片，然后将写入请求会被路由到对应的主分片。

##### 2、写入主分片

数据首先被写入到指定的主分片，主分片在处理完写入操作后，会将同样的写入请求并行发送到所有对应的副本本分片。

##### 3、同步到副本

所有的副本分片接收到来自主分片的数据后，会依次进行相同的写入操作，这个过程是并行的，以提高效率。

##### 4、确认响应

只有当所有指定活跃数量的副本分片都成功写入数据后，主分片才会向客户端发送成功响应，有一个`wait_for_active_shards`参数配置，它决定了多少副本分片必须成功写入数据后，操作才被视为成功。

如果任何副本写入失败，主分片重试，直到成功或达到重试限制。

## 88、Elasticsearch 支持哪几种搜索类型？

在 Elasticsearch 中，``参数用于指定搜索的执行方式，这可以影响搜索操作的性能和结果的准确性。

在最新的 Elasticsearch 7.x 中，只支持以下两种搜索类型：

![](/images/Elasticsearch/88.jpg)

它们分别是：

- query_then_fetch（默认）
- dfs_query_then_fetch

如果更关注响应速度和资源效率，特别是在数据分布相对均匀的环境中，用``足够了，除非对查询结果的准确性和全局一致性有较高要求的应用场景。

##### 在 Elasticsearch 早期版本中还支持以下两种类型：

- query_and_fetch（7.x 已废除）
- dfs_query_fetch（5.3 已废除）

## 89、Elasticsearch 中的 query_then_fetch 怎么理解？有什么优缺点？

Elasticsearch 中的`query_then_fetch`搜索类型，它提供了一个在查询效率和结果准确性之间较好的平衡，适用于大多数标准搜索场景。

查询主要分为以下两个阶段：

##### 阶段 1：查询阶段

- 查询被发送到所有相关的分片；
- 每个分片在本地执行查询，并找到匹配的文档；
- 每个分片计算每个匹配文档的相关性得分；
- 每个分片返回文档的 ID 和得分的一个子集给协调节点；

##### 阶段 2：获取阶段

- 协调节点收到所有分片返回的文档 ID 和得分；
- 协调节点再进行全局排序，并选出最终的顶部文档；
- 协调节点根据文档 ID 从各个分片获取完整文档并返回；

---

##### 优点：

1、**可以确保全局最准确的文档**，因为协调节点再第二阶段，会对所有分片返回的结果进行全局排序。

2、**减少了网络传输的数据量**，因为只有最终确定为最相关的文档才会被完整地从分片检索并传输到协调节点。

##### 缺点：

1、**可能会导致查询延迟**，因为需要两个阶段来完成查询，特别是再文档数量很大或分片很多的情况下。

2、**在大规模集群中可能有性能瓶颈**，因为协调节点需要处理来自所有分片的得分和文档 ID，进行排序和数据合并。

## 90、Elasticsearch 中的 dfs_query_fetch 怎么理解？有什么优缺点？

从名称上看，**dfs_query_then_fetch**比**query_then_fetch**其实就是多了一个[**DFS**]步骤。

##### 阶段 1：DFS

DFS 即**Distributed Frequency Search**，它首先在所有相关的分片上进行一次分布式词频统计，然后收集全局的词项频率和文档频率。

> 这些统计信息可以帮助系统更准确地评估词项的重要性，因为它们考虑了整个索引的数据，而不仅仅是单个分片上的数据。

##### 阶段 2：查询和获取

这里也就是执行标准的**query_then_fetch**流程。

---

##### 优点：

最大的优点就是可以获得更高的查询准确性，因为通过使用全局的词项频率，它可以更准确地计算文档的相关性得分，特别是在数据分布不均匀的分片环境中。

##### 缺点：

最大的缺点就是性能和资源开销较大，因为在执行实际的查询之前，还要进行一次额外的全局统计信息收集工作，这显著增加了查询的延迟和处理时间。

---

总的来说，`dfs_query_then_fetch`提供了一种高精度的查询方式，特别适合于哪些对查询结果的准确性和全局一致性有较高要求的应用场景。

但是，由于其较高的资源和性能开销，请慎重使用，一般只在确实需要时才使用此搜索类型。

## 91、Elasticsearch 中的 query_and_fetch 怎么理解？有什么优缺点？

在`query_and_fetch`搜索类型中，查询执行的过程较为直接：

- 查询被发送到所有相关的分片；
- 每个分片独立执行查询，并在本地计算每个文档的相关性得分；
- 每个分片立即返回完整的文档数据，而不仅仅是文档 ID 和得分；

由于每个分片已经返回了完整的文档数据，所以不再像`query_then_fetch`需要额外的获取阶段，协调节点只需要对所有返回的文档进行合并和排序即可。

---

##### 优点：

1、**响应比较快**，因为省略了单独的获取阶段，特别是在查询结果较少时的情况下。

2、**整个查询过程较为简单**，因为每个分片直接返回了完整的文档数据，减少了协调节点的处理工作。

##### 缺点：

1、**资源消耗和网络负载较高**，因为每个分片返回的都是完整的文档数据，如果是匹配的文档数量较多时，会导致大量的数据在网络中传输，每个分片和协调节点的资源消耗也会更高。

2、**缺乏全局排序准确性**，因为每个分片独立进行排序，协调节点只是简单地合并这些结果，这可能导致返回的结果在全局上不是最相关（准确）的。

> **注意**：由于全局排序准确性、网络负载问题，**query_and_fetch 搜索类型在 Elasticsearch 7.x 中已废除**，推荐使用**query_then_fetch**搜索类型。

## 92、Elasticsearch 中的 dfs_query_and_fetch 怎么理解？有什么优缺点？

和**dfs_query_then_fetch**一样，**dfs_query_and_fetch**比**query_and_fetch**其实就是多了一个[DFS]步骤，即 DFS + query_and_fetch 的组合。

> 详细原理可参考 dfs_query_then_fetch 搜索类型。
>
> **注意**：由于全局排序准确性、网络负载和性能开销问题，**dfs_query_and_fetch 搜索类型在 Elasticsearch 5.3 中已废除**，推荐使用**dfs_query_then_fetch**搜索类型。

## 93、Elasticsearch 搜索 Query 和 Filter 的区别及适用场景？哪个更快？

##### Query（查询）

Query 查询主要用于执行全文搜索，它不仅检查数据是否匹配，还能计算匹配的相关性或得分（score），查询结果是根据相关性得分排序的，最相关的文档排在最前面。

所以，Query 查询适用于需要评估和排序文档相关性的场景，如：全文搜索。

##### Filter（过滤）

Filter 过滤用于快速确定哪些文档符合指定的条件，但它不计算任何相关性得分，适用于结构化的数据，因为 Elasticsearch 会缓存过滤的结果，它可以非常快速地执行。

所以，Filter 过滤适用于需要快速、精确查找符合特定条件的文档的场景，如：精确搜索、范围搜索，状态搜索。

---

##### 哪个更快？

由于 Query 需要计算得分，而 Filter 无需计算得分还能将结果缓存，所以，**Filter 通常比 Query 要更快，更节省资源。**

---

##### 结合使用

在实际应用中，经常会将查询和过滤结合使用，已利用各自的优势。

比如，可以使用查询来找到与搜索词相关的文档，同时使用过滤来限制结果必须符合某些固定条件，如日期范围、用户权限等。

示例代码：

![](/images/Elasticsearch/93.jpg)

## 94、Elasticsearch 查询执行偏好有哪些？

Elasticsearch 支持多种查询执行偏好（），可以更细致地控制查询的执行方式，比如从特定的分片去读取数据，优先从某个分片读取数据等等。

以下是一些常见的查询执行偏好及其描述：

| 执行偏好        | 描述                                                                   |
| --------------- | ---------------------------------------------------------------------- |
| \_primary       | 只从主分片上执行查询                                                   |
| \_primary_first | 优先从主分片执行查询，主分片不可用则从副本分片查询                     |
| \_replica       | 只从副本分片执行查询                                                   |
| \_replica_first | 优先从副本分片执行查询，副本分片不可用则从主分片查询                   |
| \_only_nodes    | 仅在指定的节点上执行查询，需要指定节点的 ID 或者节点名称的一部分       |
| \_prefer_nodes  | 优先在指定的节点上执行查询，指定节点不可用，查询可以在其他节点上执行   |
| \_shards        | 直接指定查询应该在哪个分片上执行，通过分片 ID 指定                     |
| \_local         | 优先在本地节点上执行查询，本地节点不持有所需的分片，则在其他节点上执行 |
| \_only_local    | 仅在本地节点上执行查询，本地节点不持有所需的分片，则查询失败           |
| 自定义字符串    | 使用任意字符串作为偏好值，确保相同字符串的查询在同一个分片上执行。     |

示例代码：

![](/images/Elasticsearch/94.jpg)

## 95、Elasticsearch 负载均衡算法的原理？

在 Elasticsearch 中，**负载均衡算法针对的是读操作，即查询请求**，主要涉及如何在集群中的节点和分片之间高效、均匀地分配查询请求。

##### 主要步骤如下：

1、当一个查询请求到达 Elasticsearch 集群时，首先根据负载情况路由到一个协调节点。

2、协调节点负责解析查询请求，确定所有相关的主分片和副本分片。

3、协调节点根据分片负载情况，选择一个最佳的分片来执行查询。

4、协调节点返回分片所查询到的数据。

## 96、Elasticsearch 中的索引段是什么？

Elasticsearch 基于 Lucene 构建，Lucene 中的索引是由多个[**段（segment）**]组成的，因此每个 Elasticsearch 的段实际上是由一个或多个 Lucene 索引文件组成的。

每个段本身是一个完整的倒排索引，被存储在磁盘上，它是构成 Elasticsearch 索引的基本单位。

**段（segment）是不可变的**，一旦一个段被写入磁盘，它的内容就不能被修改，即所有的更新操作都会创建新的段，同时删除旧的段。

## 97、Elasticsearch 中的段合并的过程及作用？

##### 段合并的过程：

1、在进行段合并操作时，Elasticsearch 会选择若干个较小的段作为合并的对象。

2、在这个过程中，Lucene 会从这些小段中筛选出有效数据（即未被标记为删除的数据），并将这些数据保存到一个全新的段中。

3、段合并完成后，原有的那些小段会被从硬盘上物理删除，以释放存储空间。

> 段合并过程中，并不会影响正常的索引和搜索，段合并完，老的段被删除，新的段再被代开用来搜索。

---

##### 段合并的所用：

1、通过合并小的段来形成更大的段，可以减少必须查询的段的数量，从而优化查询性能。

2、合并过程还包括清理那些被标记为删除的文档，有助于减少磁盘空间的使用，进一步提高查询效率。

3、合并后可以优化索引结构，提高索引和查询的性能。

## 98、Elasticsearch 怎么进行段合并？

##### 1、自动段合并

Elasticsearch 有一个后台线程持续监控索引的情况，根据配置的合并策略（如段大小、数量等），当达到一定条件时，Elasticsearch 会自动触发段合并过程。

这个过程是不断进行的，以确保索引保持在最优状态。

##### 2、手动触发段合并

除了自动合并外，Elasticsearch 也提供了 API 允许手动触发段合并，这对于特定的维护场景非常有用，比如在大量数据删除后手动触发合并以释放空间。

##### 比如可以在业务低峰期（如每天凌晨），定时对索引做多合并操作，以释放空间。

示例代码：

> POST /test/\_forcemerge?max_num_segments=5

上面的命令会将索引`test`的段数强制合并到 5 个，其中`max_num_segments`参数用于指定合并后的目标段数。

> ##### 需要注意的是：
>
> 段合并是一个资源密集型的操作，特别是在 CPU 和 I/O 方面的消耗相当显著。
>
> 此外，由于 Elasticsearch 的自动刷新机制通常每秒会创建一个新的段，这可能会在短时间内导致段的数量急剧增加。
>
> 所以，合理控制段合并的频率和执行时机就显得尤为重要，以避免对 Elasticsearch 集群的性能造成不利影响。

## 99、Elasticsearch 事务日志的作用？

如图所示：

![](/images/Elasticsearch/99.jpg)

由于内存缓冲区（Memory Buffer）和文件系统缓存（File System Cache）都是**基于内存的存储机制**，它们在服务器宕机的情况下无法保持数据的持久性，即数据可能会丢失。

所以，**为了确保数据的可靠性，Elasticsearch 加了个 translog 事务日志文件**，当数据被写入内存缓冲区时，有时又会写入到磁盘的 translog 事务日志文件中。

这样，当机器发生宕机或者其他异常时，**Elasticsearch 重启时会读取 translog 事务日志文件，并将这些数据恢复到内存缓冲区和文件系统缓存中去**，从而保证了数据在崩溃后的完整性和一致性。

## 100、Elasticsearch 支持哪几种类型的缓存？

Elasticsearch 使用多种缓存机制来提高搜索和索引性能，这些缓存帮助重复计算和数据读取的需要，从而加快响应时间。

Elasticsearch 支持的 3 种缓存机制：

##### 1、节点请求缓存（Node Query Cache）

节点请求缓存，是节点级别的，它是针对每个节点上的所有分片查询结果的缓存，被所有分片共享。

##### 2、分片请求缓存（Shard Request Cache）

分片请求缓存，是分片级别的，它特别针对单个分片的请求结果进行缓存。

##### 3、字段数据缓存（FieId Data Cache）

字段数据缓存用于存储聚合操作中用到的字段数据。

## 101、Elasticsearch 如何做性能调优？

![](/images/Elasticsearch/101.jpg)

## 102、Elasticsearch 如何提高写入速度？

Elasticsearch 针对搜索的性能要求不太高，但写入速度是许多使用场景中的关键需求，特别是在日志分析、实时数据处理等领域。

常用的写入性能的优化策略：

##### 1、批量操作

使用 Elasticsearch 的 Bulk API 来执行批量写入操作，它通过将多个写入操作（）组合到单个 API 调用中，可以显著减少网络开销和减少多次单独写入操作的处理时间。

另外，调整线程池的大小和对立容量可以确保批量操作得到高效处理，防止线程池饱和或过多任务排队等待，从而优化整体写入性能。

##### 2、增加索引刷新间隔

在大量数据写入时，可以将索引的刷新间隔设置得更长一些，这样可以减少索引操作的开销。

增加索引的刷新间隔意味着生成 segment 合并的次数，这有助于降低由于合并操作引起的 CPU 和 I/O 负载。

##### 3、增加 Translog 刷新间隔

默认情况下，Translog 会定期被刷新到磁盘上，以保证数据的持久性。通过增加这个刷新（flush）间隔，可以减少磁盘写入操作的频率，从而降低 IOPS（每秒输入输出操作次数）和减少因频繁写入导致的性能阻塞。

## 103、Elasticsearch 内存优化管理如何做？

在管理 Elasticsearch 集群时，合理配置和监控内存使用是确保系统性能和稳定性的关键。

以下是一些易于理解的关键策略：

##### 1、倒排索引的内存管理

倒排索引是 Elasticsearch 快速搜索的核心，它必须常驻内存以确保搜索效率。这部分内存不会被 JVM 的垃圾回收管理，因此，监控数据节点上的段内存（segment memory）增长趋势是必须的，以预防内存溢出。

##### 2、缓存大小设置

Elasticsearch 提供了多种缓存机制，这些缓存的大小需要根据实际使用情况合理设置。

##### 3、优化大数据量的处理

避免执行返回大量结果集的搜索和聚合查询，这类操作会占用大量内存并增加系统负担。

对于需要处理大量数据的场景，建议使用 scan & scroll API，它可以分批次安全地拉取数据，减少对内存的一次性需求。

##### 4、集群内存无法水平扩展的管理

Elasticsearch 的某些统计数据（如 cluster stats）占用的内存无法通过添加更多节点来水平扩展，对于超大规模的集群，可以考虑将其分拆成多个小集群，并通过 CSS（Cross-Cluster Search）跨集群搜索功能来管理这些集群。

##### 5、持续监控内存使用

要确保有足够的堆内存对业务需求，必须结合实际应用场景对集群的堆内存使用情况进行持续监控。这包括定期检查各种缓存的使用情况和倒排索引的内存占用，以及调整配置以优化内存使用。

## 104、Elasticsearch 冷热数据分离怎么做？

可以将热数据存储到 SSD，以提高检索效率，然后将冷数据定期进行 Shrink 操作，即减少冷数据所占用的分片数量，从而降低资源消耗。

区分冷热节点：

- **热节点**：一般要配备高 IOPS 的 SSD，以支持高速数据读写和访问，这些节点可能还会有较大的内存以支持大量的并发查询和缓存需求。
- **冷节点**：一般使用容量更大、成本更低的 HDD，由于这些数据的访问频率低，所以可以接受较长的访问延迟。

然后借助 ES 中的 ILM 策略，它可以为每种数据类型定义生命周期策略，包括何时从热节点移动到冷节点，自动管理数据以实现在不同节点之间的迁移。

> ILM 的全称是**Index Lifecycle Management**，即**索引生命周期管理**。
>
> ILM 是 Elasticsearch 提供的一种功能，用于帮助用户自动管理索引从创建到最终删除的整个生命周期。通过定义不同的策略，可以控制索引在其生命周期的不同阶段应执行的操作，如优化、迁移、删除等，以此来优化存储和提高查询效率。

## 105、Elasticsearch 怎么从 MySQL 同步数据？

##### 主要有以下三种方案：

1、官方数据收集和同步组件：logstash

2、阿里开源的 canal

3、go-mysql-elasticsearch
